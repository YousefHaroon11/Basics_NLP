{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a46f40e-33c2-4051-b408-229c4ee6bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "text='''In the middle part of his career, Einstein made important contributions\n",
    "to statistical mechanics and quantum theory. Especially notable was his work on the\n",
    "quantum physics of radiation, in which light consists of particles, subsequently called photons.\n",
    "With physicist Satyendra Nath Bose, he laid the groundwork for Bose–Einstein statistics.\n",
    "For much of the last phase of his academic life,\n",
    "Einstein worked on two endeavors that ultimately proved unsuccessful.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01e0716f-b697-45b5-a7fb-459f06596509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word is :  In\n",
      "POS is :  85 === ADP === adposition\n",
      "Dep is :  443 === prep === prepositional modifier\n",
      "Tag is :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "====================================\n",
      "Word is :  the\n",
      "POS is :  90 === DET === determiner\n",
      "Dep is :  415 === det === determiner\n",
      "Tag is :  15267657372422890137 === DT === determiner\n",
      "====================================\n",
      "Word is :  middle\n",
      "POS is :  84 === ADJ === adjective\n",
      "Dep is :  402 === amod === adjectival modifier\n",
      "Tag is :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "====================================\n",
      "Word is :  part\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  439 === pobj === object of preposition\n",
      "Tag is :  15308085513773655218 === NN === noun, singular or mass\n",
      "====================================\n",
      "Word is :  of\n",
      "POS is :  85 === ADP === adposition\n",
      "Dep is :  443 === prep === prepositional modifier\n",
      "Tag is :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "====================================\n",
      "Word is :  his\n",
      "POS is :  95 === PRON === pronoun\n",
      "Dep is :  440 === poss === possession modifier\n",
      "Tag is :  4062917326063685704 === PRP$ === pronoun, possessive\n",
      "====================================\n",
      "Word is :  career\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  439 === pobj === object of preposition\n",
      "Tag is :  15308085513773655218 === NN === noun, singular or mass\n",
      "====================================\n",
      "Word is :  ,\n",
      "POS is :  97 === PUNCT === punctuation\n",
      "Dep is :  445 === punct === punctuation\n",
      "Tag is :  2593208677638477497 === , === punctuation mark, comma\n",
      "====================================\n",
      "Word is :  Einstein\n",
      "POS is :  96 === PROPN === proper noun\n",
      "Dep is :  429 === nsubj === nominal subject\n",
      "Tag is :  15794550382381185553 === NNP === noun, proper singular\n",
      "====================================\n",
      "Word is :  made\n",
      "POS is :  100 === VERB === verb\n",
      "Dep is :  8206900633647566924 === ROOT === root\n",
      "Tag is :  17109001835818727656 === VBD === verb, past tense\n",
      "====================================\n",
      "Word is :  important\n",
      "POS is :  84 === ADJ === adjective\n",
      "Dep is :  402 === amod === adjectival modifier\n",
      "Tag is :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "====================================\n",
      "Word is :  contributions\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  416 === dobj === direct object\n",
      "Tag is :  783433942507015291 === NNS === noun, plural\n",
      "====================================\n",
      "Word is :  \n",
      "\n",
      "POS is :  103 === SPACE === space\n",
      "Dep is :  414 === dep === unclassified dependent\n",
      "Tag is :  6893682062797376370 === _SP === whitespace\n",
      "====================================\n",
      "Word is :  to\n",
      "POS is :  85 === ADP === adposition\n",
      "Dep is :  443 === prep === prepositional modifier\n",
      "Tag is :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "====================================\n",
      "Word is :  statistical\n",
      "POS is :  84 === ADJ === adjective\n",
      "Dep is :  402 === amod === adjectival modifier\n",
      "Tag is :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "====================================\n",
      "Word is :  mechanics\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  439 === pobj === object of preposition\n",
      "Tag is :  783433942507015291 === NNS === noun, plural\n",
      "====================================\n",
      "Word is :  and\n",
      "POS is :  89 === CCONJ === coordinating conjunction\n",
      "Dep is :  407 === cc === coordinating conjunction\n",
      "Tag is :  17571114184892886314 === CC === conjunction, coordinating\n",
      "====================================\n",
      "Word is :  quantum\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  7037928807040764755 === compound === compound\n",
      "Tag is :  15308085513773655218 === NN === noun, singular or mass\n",
      "====================================\n",
      "Word is :  theory\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  410 === conj === conjunct\n",
      "Tag is :  15308085513773655218 === NN === noun, singular or mass\n",
      "====================================\n",
      "Word is :  .\n",
      "POS is :  97 === PUNCT === punctuation\n",
      "Dep is :  445 === punct === punctuation\n",
      "Tag is :  12646065887601541794 === . === punctuation mark, sentence closer\n",
      "====================================\n",
      "Word is :  Especially\n",
      "POS is :  86 === ADV === adverb\n",
      "Dep is :  400 === advmod === adverbial modifier\n",
      "Tag is :  164681854541413346 === RB === adverb\n",
      "====================================\n",
      "Word is :  notable\n",
      "POS is :  84 === ADJ === adjective\n",
      "Dep is :  398 === acomp === adjectival complement\n",
      "Tag is :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "====================================\n",
      "Word is :  was\n",
      "POS is :  87 === AUX === auxiliary\n",
      "Dep is :  8206900633647566924 === ROOT === root\n",
      "Tag is :  17109001835818727656 === VBD === verb, past tense\n",
      "====================================\n",
      "Word is :  his\n",
      "POS is :  95 === PRON === pronoun\n",
      "Dep is :  440 === poss === possession modifier\n",
      "Tag is :  4062917326063685704 === PRP$ === pronoun, possessive\n",
      "====================================\n",
      "Word is :  work\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  429 === nsubj === nominal subject\n",
      "Tag is :  15308085513773655218 === NN === noun, singular or mass\n",
      "====================================\n",
      "Word is :  on\n",
      "POS is :  85 === ADP === adposition\n",
      "Dep is :  443 === prep === prepositional modifier\n",
      "Tag is :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "====================================\n",
      "Word is :  the\n",
      "POS is :  90 === DET === determiner\n",
      "Dep is :  415 === det === determiner\n",
      "Tag is :  15267657372422890137 === DT === determiner\n",
      "====================================\n",
      "Word is :  \n",
      "\n",
      "POS is :  103 === SPACE === space\n",
      "Dep is :  414 === dep === unclassified dependent\n",
      "Tag is :  6893682062797376370 === _SP === whitespace\n",
      "====================================\n",
      "Word is :  quantum\n",
      "POS is :  84 === ADJ === adjective\n",
      "Dep is :  402 === amod === adjectival modifier\n",
      "Tag is :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "====================================\n",
      "Word is :  physics\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  439 === pobj === object of preposition\n",
      "Tag is :  15308085513773655218 === NN === noun, singular or mass\n",
      "====================================\n",
      "Word is :  of\n",
      "POS is :  85 === ADP === adposition\n",
      "Dep is :  443 === prep === prepositional modifier\n",
      "Tag is :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "====================================\n",
      "Word is :  radiation\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  439 === pobj === object of preposition\n",
      "Tag is :  15308085513773655218 === NN === noun, singular or mass\n",
      "====================================\n",
      "Word is :  ,\n",
      "POS is :  97 === PUNCT === punctuation\n",
      "Dep is :  445 === punct === punctuation\n",
      "Tag is :  2593208677638477497 === , === punctuation mark, comma\n",
      "====================================\n",
      "Word is :  in\n",
      "POS is :  85 === ADP === adposition\n",
      "Dep is :  443 === prep === prepositional modifier\n",
      "Tag is :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "====================================\n",
      "Word is :  which\n",
      "POS is :  95 === PRON === pronoun\n",
      "Dep is :  439 === pobj === object of preposition\n",
      "Tag is :  17202369883303991778 === WDT === wh-determiner\n",
      "====================================\n",
      "Word is :  light\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  429 === nsubj === nominal subject\n",
      "Tag is :  15308085513773655218 === NN === noun, singular or mass\n",
      "====================================\n",
      "Word is :  consists\n",
      "POS is :  100 === VERB === verb\n",
      "Dep is :  447 === relcl === relative clause modifier\n",
      "Tag is :  13927759927860985106 === VBZ === verb, 3rd person singular present\n",
      "====================================\n",
      "Word is :  of\n",
      "POS is :  85 === ADP === adposition\n",
      "Dep is :  443 === prep === prepositional modifier\n",
      "Tag is :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "====================================\n",
      "Word is :  particles\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  439 === pobj === object of preposition\n",
      "Tag is :  783433942507015291 === NNS === noun, plural\n",
      "====================================\n",
      "Word is :  ,\n",
      "POS is :  97 === PUNCT === punctuation\n",
      "Dep is :  445 === punct === punctuation\n",
      "Tag is :  2593208677638477497 === , === punctuation mark, comma\n",
      "====================================\n",
      "Word is :  subsequently\n",
      "POS is :  86 === ADV === adverb\n",
      "Dep is :  400 === advmod === adverbial modifier\n",
      "Tag is :  164681854541413346 === RB === adverb\n",
      "====================================\n",
      "Word is :  called\n",
      "POS is :  100 === VERB === verb\n",
      "Dep is :  399 === advcl === adverbial clause modifier\n",
      "Tag is :  3822385049556375858 === VBN === verb, past participle\n",
      "====================================\n",
      "Word is :  photons\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  416 === dobj === direct object\n",
      "Tag is :  783433942507015291 === NNS === noun, plural\n",
      "====================================\n",
      "Word is :  .\n",
      "POS is :  97 === PUNCT === punctuation\n",
      "Dep is :  445 === punct === punctuation\n",
      "Tag is :  12646065887601541794 === . === punctuation mark, sentence closer\n",
      "====================================\n",
      "Word is :  \n",
      "\n",
      "POS is :  103 === SPACE === space\n",
      "Dep is :  414 === dep === unclassified dependent\n",
      "Tag is :  6893682062797376370 === _SP === whitespace\n",
      "====================================\n",
      "Word is :  With\n",
      "POS is :  85 === ADP === adposition\n",
      "Dep is :  443 === prep === prepositional modifier\n",
      "Tag is :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "====================================\n",
      "Word is :  physicist\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  7037928807040764755 === compound === compound\n",
      "Tag is :  15308085513773655218 === NN === noun, singular or mass\n",
      "====================================\n",
      "Word is :  Satyendra\n",
      "POS is :  96 === PROPN === proper noun\n",
      "Dep is :  7037928807040764755 === compound === compound\n",
      "Tag is :  15794550382381185553 === NNP === noun, proper singular\n",
      "====================================\n",
      "Word is :  Nath\n",
      "POS is :  96 === PROPN === proper noun\n",
      "Dep is :  7037928807040764755 === compound === compound\n",
      "Tag is :  15794550382381185553 === NNP === noun, proper singular\n",
      "====================================\n",
      "Word is :  Bose\n",
      "POS is :  96 === PROPN === proper noun\n",
      "Dep is :  439 === pobj === object of preposition\n",
      "Tag is :  15794550382381185553 === NNP === noun, proper singular\n",
      "====================================\n",
      "Word is :  ,\n",
      "POS is :  97 === PUNCT === punctuation\n",
      "Dep is :  445 === punct === punctuation\n",
      "Tag is :  2593208677638477497 === , === punctuation mark, comma\n",
      "====================================\n",
      "Word is :  he\n",
      "POS is :  95 === PRON === pronoun\n",
      "Dep is :  429 === nsubj === nominal subject\n",
      "Tag is :  13656873538139661788 === PRP === pronoun, personal\n",
      "====================================\n",
      "Word is :  laid\n",
      "POS is :  100 === VERB === verb\n",
      "Dep is :  8206900633647566924 === ROOT === root\n",
      "Tag is :  17109001835818727656 === VBD === verb, past tense\n",
      "====================================\n",
      "Word is :  the\n",
      "POS is :  90 === DET === determiner\n",
      "Dep is :  415 === det === determiner\n",
      "Tag is :  15267657372422890137 === DT === determiner\n",
      "====================================\n",
      "Word is :  groundwork\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  416 === dobj === direct object\n",
      "Tag is :  15308085513773655218 === NN === noun, singular or mass\n",
      "====================================\n",
      "Word is :  for\n",
      "POS is :  85 === ADP === adposition\n",
      "Dep is :  443 === prep === prepositional modifier\n",
      "Tag is :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "====================================\n",
      "Word is :  Bose\n",
      "POS is :  96 === PROPN === proper noun\n",
      "Dep is :  426 === nmod === modifier of nominal\n",
      "Tag is :  15794550382381185553 === NNP === noun, proper singular\n",
      "====================================\n",
      "Word is :  –\n",
      "POS is :  97 === PUNCT === punctuation\n",
      "Dep is :  445 === punct === punctuation\n",
      "Tag is :  11532473245541075862 === : === punctuation mark, colon or ellipsis\n",
      "====================================\n",
      "Word is :  Einstein\n",
      "POS is :  96 === PROPN === proper noun\n",
      "Dep is :  7037928807040764755 === compound === compound\n",
      "Tag is :  15794550382381185553 === NNP === noun, proper singular\n",
      "====================================\n",
      "Word is :  statistics\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  439 === pobj === object of preposition\n",
      "Tag is :  783433942507015291 === NNS === noun, plural\n",
      "====================================\n",
      "Word is :  .\n",
      "POS is :  97 === PUNCT === punctuation\n",
      "Dep is :  445 === punct === punctuation\n",
      "Tag is :  12646065887601541794 === . === punctuation mark, sentence closer\n",
      "====================================\n",
      "Word is :  \n",
      "\n",
      "POS is :  103 === SPACE === space\n",
      "Dep is :  414 === dep === unclassified dependent\n",
      "Tag is :  6893682062797376370 === _SP === whitespace\n",
      "====================================\n",
      "Word is :  For\n",
      "POS is :  85 === ADP === adposition\n",
      "Dep is :  443 === prep === prepositional modifier\n",
      "Tag is :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "====================================\n",
      "Word is :  much\n",
      "POS is :  84 === ADJ === adjective\n",
      "Dep is :  439 === pobj === object of preposition\n",
      "Tag is :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "====================================\n",
      "Word is :  of\n",
      "POS is :  85 === ADP === adposition\n",
      "Dep is :  443 === prep === prepositional modifier\n",
      "Tag is :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "====================================\n",
      "Word is :  the\n",
      "POS is :  90 === DET === determiner\n",
      "Dep is :  415 === det === determiner\n",
      "Tag is :  15267657372422890137 === DT === determiner\n",
      "====================================\n",
      "Word is :  last\n",
      "POS is :  84 === ADJ === adjective\n",
      "Dep is :  402 === amod === adjectival modifier\n",
      "Tag is :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "====================================\n",
      "Word is :  phase\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  439 === pobj === object of preposition\n",
      "Tag is :  15308085513773655218 === NN === noun, singular or mass\n",
      "====================================\n",
      "Word is :  of\n",
      "POS is :  85 === ADP === adposition\n",
      "Dep is :  443 === prep === prepositional modifier\n",
      "Tag is :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "====================================\n",
      "Word is :  his\n",
      "POS is :  95 === PRON === pronoun\n",
      "Dep is :  440 === poss === possession modifier\n",
      "Tag is :  4062917326063685704 === PRP$ === pronoun, possessive\n",
      "====================================\n",
      "Word is :  academic\n",
      "POS is :  84 === ADJ === adjective\n",
      "Dep is :  402 === amod === adjectival modifier\n",
      "Tag is :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "====================================\n",
      "Word is :  life\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  439 === pobj === object of preposition\n",
      "Tag is :  15308085513773655218 === NN === noun, singular or mass\n",
      "====================================\n",
      "Word is :  ,\n",
      "POS is :  97 === PUNCT === punctuation\n",
      "Dep is :  445 === punct === punctuation\n",
      "Tag is :  2593208677638477497 === , === punctuation mark, comma\n",
      "====================================\n",
      "Word is :  \n",
      "\n",
      "POS is :  103 === SPACE === space\n",
      "Dep is :  414 === dep === unclassified dependent\n",
      "Tag is :  6893682062797376370 === _SP === whitespace\n",
      "====================================\n",
      "Word is :  Einstein\n",
      "POS is :  96 === PROPN === proper noun\n",
      "Dep is :  429 === nsubj === nominal subject\n",
      "Tag is :  15794550382381185553 === NNP === noun, proper singular\n",
      "====================================\n",
      "Word is :  worked\n",
      "POS is :  100 === VERB === verb\n",
      "Dep is :  8206900633647566924 === ROOT === root\n",
      "Tag is :  17109001835818727656 === VBD === verb, past tense\n",
      "====================================\n",
      "Word is :  on\n",
      "POS is :  85 === ADP === adposition\n",
      "Dep is :  443 === prep === prepositional modifier\n",
      "Tag is :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "====================================\n",
      "Word is :  two\n",
      "POS is :  93 === NUM === numeral\n",
      "Dep is :  12837356684637874264 === nummod === numeric modifier\n",
      "Tag is :  8427216679587749980 === CD === cardinal number\n",
      "====================================\n",
      "Word is :  endeavors\n",
      "POS is :  92 === NOUN === noun\n",
      "Dep is :  439 === pobj === object of preposition\n",
      "Tag is :  783433942507015291 === NNS === noun, plural\n",
      "====================================\n",
      "Word is :  that\n",
      "POS is :  95 === PRON === pronoun\n",
      "Dep is :  429 === nsubj === nominal subject\n",
      "Tag is :  17202369883303991778 === WDT === wh-determiner\n",
      "====================================\n",
      "Word is :  ultimately\n",
      "POS is :  86 === ADV === adverb\n",
      "Dep is :  400 === advmod === adverbial modifier\n",
      "Tag is :  164681854541413346 === RB === adverb\n",
      "====================================\n",
      "Word is :  proved\n",
      "POS is :  100 === VERB === verb\n",
      "Dep is :  447 === relcl === relative clause modifier\n",
      "Tag is :  17109001835818727656 === VBD === verb, past tense\n",
      "====================================\n",
      "Word is :  unsuccessful\n",
      "POS is :  84 === ADJ === adjective\n",
      "Dep is :  433 === oprd === object predicate\n",
      "Tag is :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "====================================\n",
      "Word is :  .\n",
      "POS is :  97 === PUNCT === punctuation\n",
      "Dep is :  445 === punct === punctuation\n",
      "Tag is :  12646065887601541794 === . === punctuation mark, sentence closer\n",
      "====================================\n",
      "Word is :  \n",
      "\n",
      "POS is :  103 === SPACE === space\n",
      "Dep is :  414 === dep === unclassified dependent\n",
      "Tag is :  6893682062797376370 === _SP === whitespace\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "doc=nlp('''In the middle part of his career, Einstein made important contributions\n",
    "to statistical mechanics and quantum theory. Especially notable was his work on the\n",
    "quantum physics of radiation, in which light consists of particles, subsequently called photons.\n",
    "With physicist Satyendra Nath Bose, he laid the groundwork for Bose–Einstein statistics.\n",
    "For much of the last phase of his academic life,\n",
    "Einstein worked on two endeavors that ultimately proved unsuccessful.\n",
    "''')\n",
    "for token in doc:\n",
    "    print(\"Word is : \",token.text)\n",
    "    print(\"POS is : \",token.pos,\"===\",token.pos_,\"===\",spacy.explain(token.pos_))\n",
    "    print(\"Dep is : \",token.dep,\"===\",token.dep_,\"===\",spacy.explain(token.dep_))\n",
    "    print(\"Tag is : \",token.tag,\"===\",token.tag_,\"===\",spacy.explain(token.tag_))\n",
    "    print(\"====================================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b39a8b3-c70c-459e-bb00-b31404dacb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In         ADP      IN     conjunction, subordinating or preposition\n",
      "the        DET      DT     determiner\n",
      "middle     ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "part       NOUN     NN     noun, singular or mass\n",
      "of         ADP      IN     conjunction, subordinating or preposition\n",
      "his        PRON     PRP$   pronoun, possessive\n",
      "career     NOUN     NN     noun, singular or mass\n",
      ",          PUNCT    ,      punctuation mark, comma\n",
      "Einstein   PROPN    NNP    noun, proper singular\n",
      "made       VERB     VBD    verb, past tense\n",
      "important  ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "contributions NOUN     NNS    noun, plural\n",
      "\n",
      "          SPACE    _SP    whitespace\n",
      "to         ADP      IN     conjunction, subordinating or preposition\n",
      "statistical ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "mechanics  NOUN     NNS    noun, plural\n",
      "and        CCONJ    CC     conjunction, coordinating\n",
      "quantum    NOUN     NN     noun, singular or mass\n",
      "theory     NOUN     NN     noun, singular or mass\n",
      ".          PUNCT    .      punctuation mark, sentence closer\n",
      "Especially ADV      RB     adverb\n",
      "notable    ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "was        AUX      VBD    verb, past tense\n",
      "his        PRON     PRP$   pronoun, possessive\n",
      "work       NOUN     NN     noun, singular or mass\n",
      "on         ADP      IN     conjunction, subordinating or preposition\n",
      "the        DET      DT     determiner\n",
      "\n",
      "          SPACE    _SP    whitespace\n",
      "quantum    ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "physics    NOUN     NN     noun, singular or mass\n",
      "of         ADP      IN     conjunction, subordinating or preposition\n",
      "radiation  NOUN     NN     noun, singular or mass\n",
      ",          PUNCT    ,      punctuation mark, comma\n",
      "in         ADP      IN     conjunction, subordinating or preposition\n",
      "which      PRON     WDT    wh-determiner\n",
      "light      NOUN     NN     noun, singular or mass\n",
      "consists   VERB     VBZ    verb, 3rd person singular present\n",
      "of         ADP      IN     conjunction, subordinating or preposition\n",
      "particles  NOUN     NNS    noun, plural\n",
      ",          PUNCT    ,      punctuation mark, comma\n",
      "subsequently ADV      RB     adverb\n",
      "called     VERB     VBN    verb, past participle\n",
      "photons    NOUN     NNS    noun, plural\n",
      ".          PUNCT    .      punctuation mark, sentence closer\n",
      "\n",
      "          SPACE    _SP    whitespace\n",
      "With       ADP      IN     conjunction, subordinating or preposition\n",
      "physicist  NOUN     NN     noun, singular or mass\n",
      "Satyendra  PROPN    NNP    noun, proper singular\n",
      "Nath       PROPN    NNP    noun, proper singular\n",
      "Bose       PROPN    NNP    noun, proper singular\n",
      ",          PUNCT    ,      punctuation mark, comma\n",
      "he         PRON     PRP    pronoun, personal\n",
      "laid       VERB     VBD    verb, past tense\n",
      "the        DET      DT     determiner\n",
      "groundwork NOUN     NN     noun, singular or mass\n",
      "for        ADP      IN     conjunction, subordinating or preposition\n",
      "Bose       PROPN    NNP    noun, proper singular\n",
      "–          PUNCT    :      punctuation mark, colon or ellipsis\n",
      "Einstein   PROPN    NNP    noun, proper singular\n",
      "statistics NOUN     NNS    noun, plural\n",
      ".          PUNCT    .      punctuation mark, sentence closer\n",
      "\n",
      "          SPACE    _SP    whitespace\n",
      "For        ADP      IN     conjunction, subordinating or preposition\n",
      "much       ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "of         ADP      IN     conjunction, subordinating or preposition\n",
      "the        DET      DT     determiner\n",
      "last       ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "phase      NOUN     NN     noun, singular or mass\n",
      "of         ADP      IN     conjunction, subordinating or preposition\n",
      "his        PRON     PRP$   pronoun, possessive\n",
      "academic   ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "life       NOUN     NN     noun, singular or mass\n",
      ",          PUNCT    ,      punctuation mark, comma\n",
      "\n",
      "          SPACE    _SP    whitespace\n",
      "Einstein   PROPN    NNP    noun, proper singular\n",
      "worked     VERB     VBD    verb, past tense\n",
      "on         ADP      IN     conjunction, subordinating or preposition\n",
      "two        NUM      CD     cardinal number\n",
      "endeavors  NOUN     NNS    noun, plural\n",
      "that       PRON     WDT    wh-determiner\n",
      "ultimately ADV      RB     adverb\n",
      "proved     VERB     VBD    verb, past tense\n",
      "unsuccessful ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      ".          PUNCT    .      punctuation mark, sentence closer\n",
      "\n",
      "          SPACE    _SP    whitespace\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f'{token.text:{10}} {token.pos_:{8}} {token.tag_:{6}} {spacy.explain(token.tag_)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f630154-2102-41d8-a85a-e4fcb50f5ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i          PRON     PRP    pronoun, personal\n",
      "read       VERB     VBD    verb, past tense\n",
      "a          DET      DT     determiner\n",
      "book       NOUN     NN     noun, singular or mass\n",
      "on         ADP      IN     conjunction, subordinating or preposition\n",
      "NLP        PROPN    NNP    noun, proper singular\n"
     ]
    }
   ],
   "source": [
    "doc1=nlp(\"i read a book on NLP\")\n",
    "for token in doc1:\n",
    "    print(f'{token.text:{10}} {token.pos_:{8}} {token.tag_:{6}} {spacy.explain(token.tag_)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ebf10b4-fda6-4864-9664-0de8a3c4bc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84. ADJ   : 9\n",
      "85. ADP   : 13\n",
      "86. ADV   : 3\n",
      "87. AUX   : 1\n",
      "89. CCONJ : 1\n",
      "90. DET   : 4\n",
      "92. NOUN  : 18\n",
      "93. NUM   : 1\n",
      "95. PRON  : 6\n",
      "96. PROPN : 7\n",
      "97. PUNCT : 10\n",
      "100. VERB  : 6\n",
      "103. SPACE : 6\n"
     ]
    }
   ],
   "source": [
    "pos_counts=doc.count_by(spacy.attrs.POS)\n",
    "for k,v in sorted(pos_counts.items()):\n",
    "    print(f'{k}. {doc.vocab[k].text:{6}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c0e46da-7ed1-4276-a1dd-3962de82a6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : Moses , type : NNS ,  means : noun, plural\n",
      "Word : supposes , type : VBZ ,  means : verb, 3rd person singular present\n",
      "Word : his , type : PRP$ ,  means : pronoun, possessive\n",
      "Word : toeses , type : NNS ,  means : noun, plural\n",
      "Word : are , type : VBP ,  means : verb, non-3rd person singular present\n",
      "Word : roses , type : NNS ,  means : noun, plural\n",
      "Word : but , type : CC ,  means : conjunction, coordinating\n",
      "Word : moses , type : VBZ ,  means : verb, 3rd person singular present\n",
      "Word : supposes , type : NNS ,  means : noun, plural\n",
      "Word : erroneously , type : RB ,  means : adverb\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "text2='Moses supposes his  toeses are roses but moses supposes erroneously'\n",
    "for w,m in nltk.pos_tag(nltk.word_tokenize(text2)):\n",
    "    print(f'Word : {w} , type : {m} ,  means : {spacy.explain(m)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95fe2051-7367-4cfd-a6cc-d9c23676659b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : In , type : IN ,  means : conjunction, subordinating or preposition\n",
      "Word : the , type : DT ,  means : determiner\n",
      "Word : middle , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "Word : part , type : NN ,  means : noun, singular or mass\n",
      "Word : of , type : IN ,  means : conjunction, subordinating or preposition\n",
      "Word : his , type : PRP$ ,  means : pronoun, possessive\n",
      "Word : career , type : NN ,  means : noun, singular or mass\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "Word : Einstein , type : NNP ,  means : noun, proper singular\n",
      "Word : made , type : VBD ,  means : verb, past tense\n",
      "Word : important , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "Word : contributions , type : NNS ,  means : noun, plural\n",
      "Word : to , type : TO ,  means : infinitival \"to\"\n",
      "Word : statistical , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "Word : mechanics , type : NNS ,  means : noun, plural\n",
      "Word : and , type : CC ,  means : conjunction, coordinating\n",
      "Word : quantum , type : NN ,  means : noun, singular or mass\n",
      "Word : theory , type : NN ,  means : noun, singular or mass\n",
      "Word : . , type : . ,  means : punctuation mark, sentence closer\n",
      "Word : Especially , type : RB ,  means : adverb\n",
      "Word : notable , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "Word : was , type : VBD ,  means : verb, past tense\n",
      "Word : his , type : PRP$ ,  means : pronoun, possessive\n",
      "Word : work , type : NN ,  means : noun, singular or mass\n",
      "Word : on , type : IN ,  means : conjunction, subordinating or preposition\n",
      "Word : the , type : DT ,  means : determiner\n",
      "Word : quantum , type : NN ,  means : noun, singular or mass\n",
      "Word : physics , type : NNS ,  means : noun, plural\n",
      "Word : of , type : IN ,  means : conjunction, subordinating or preposition\n",
      "Word : radiation , type : NN ,  means : noun, singular or mass\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "Word : in , type : IN ,  means : conjunction, subordinating or preposition\n",
      "Word : which , type : WDT ,  means : wh-determiner\n",
      "Word : light , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "Word : consists , type : NNS ,  means : noun, plural\n",
      "Word : of , type : IN ,  means : conjunction, subordinating or preposition\n",
      "Word : particles , type : NNS ,  means : noun, plural\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "Word : subsequently , type : RB ,  means : adverb\n",
      "Word : called , type : VBD ,  means : verb, past tense\n",
      "Word : photons , type : NNS ,  means : noun, plural\n",
      "Word : . , type : . ,  means : punctuation mark, sentence closer\n",
      "Word : With , type : IN ,  means : conjunction, subordinating or preposition\n",
      "Word : physicist , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "Word : Satyendra , type : NNP ,  means : noun, proper singular\n",
      "Word : Nath , type : NNP ,  means : noun, proper singular\n",
      "Word : Bose , type : NNP ,  means : noun, proper singular\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "Word : he , type : PRP ,  means : pronoun, personal\n",
      "Word : laid , type : VBD ,  means : verb, past tense\n",
      "Word : the , type : DT ,  means : determiner\n",
      "Word : groundwork , type : NN ,  means : noun, singular or mass\n",
      "Word : for , type : IN ,  means : conjunction, subordinating or preposition\n",
      "Word : Bose–Einstein , type : NNP ,  means : noun, proper singular\n",
      "Word : statistics , type : NNS ,  means : noun, plural\n",
      "Word : . , type : . ,  means : punctuation mark, sentence closer\n",
      "Word : For , type : IN ,  means : conjunction, subordinating or preposition\n",
      "Word : much , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "Word : of , type : IN ,  means : conjunction, subordinating or preposition\n",
      "Word : the , type : DT ,  means : determiner\n",
      "Word : last , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "Word : phase , type : NN ,  means : noun, singular or mass\n",
      "Word : of , type : IN ,  means : conjunction, subordinating or preposition\n",
      "Word : his , type : PRP$ ,  means : pronoun, possessive\n",
      "Word : academic , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "Word : life , type : NN ,  means : noun, singular or mass\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "Word : Einstein , type : NNP ,  means : noun, proper singular\n",
      "Word : worked , type : VBD ,  means : verb, past tense\n",
      "Word : on , type : IN ,  means : conjunction, subordinating or preposition\n",
      "Word : two , type : CD ,  means : cardinal number\n",
      "Word : endeavors , type : NNS ,  means : noun, plural\n",
      "Word : that , type : WDT ,  means : wh-determiner\n",
      "Word : ultimately , type : RB ,  means : adverb\n",
      "Word : proved , type : VBD ,  means : verb, past tense\n",
      "Word : unsuccessful , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "Word : . , type : . ,  means : punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "tokenizer=PunktSentenceTokenizer(text)\n",
    "tokenized=tokenizer.tokenize(text)\n",
    "tokenized[:5]\n",
    "for i in tokenized[:5]:\n",
    "    for w,m in nltk.pos_tag(nltk.word_tokenize(i)):\n",
    "        print(f'Word : {w} , type : {m} ,  means : {spacy.explain(m)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9537e6a7-ffa2-46f4-801f-40217ed80d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "train_text=state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text=state_union.raw(\"2006-GWBush.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e8122c4-bd9f-45f9-8e42-b9394fbac1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : PRESIDENT , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : GEORGE , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : W. , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : BUSH , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : 'S , type : POS ,  means : possessive ending\n",
      "==========================================\n",
      "Word : ADDRESS , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : BEFORE , type : IN ,  means : conjunction, subordinating or preposition\n",
      "==========================================\n",
      "Word : A , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : JOINT , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : SESSION , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : OF , type : IN ,  means : conjunction, subordinating or preposition\n",
      "==========================================\n",
      "Word : THE , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : CONGRESS , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : ON , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : THE , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : STATE , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : OF , type : IN ,  means : conjunction, subordinating or preposition\n",
      "==========================================\n",
      "Word : THE , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : UNION , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : January , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : 31 , type : CD ,  means : cardinal number\n",
      "==========================================\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "==========================================\n",
      "Word : 2006 , type : CD ,  means : cardinal number\n",
      "==========================================\n",
      "Word : THE , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : PRESIDENT , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : : , type : : ,  means : punctuation mark, colon or ellipsis\n",
      "==========================================\n",
      "Word : Thank , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : you , type : PRP ,  means : pronoun, personal\n",
      "==========================================\n",
      "Word : all , type : DT ,  means : determiner\n",
      "==========================================\n",
      "Word : . , type : . ,  means : punctuation mark, sentence closer\n",
      "==========================================\n",
      "Word : Mr. , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : Speaker , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "==========================================\n",
      "Word : Vice , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : President , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : Cheney , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "==========================================\n",
      "Word : members , type : NNS ,  means : noun, plural\n",
      "==========================================\n",
      "Word : of , type : IN ,  means : conjunction, subordinating or preposition\n",
      "==========================================\n",
      "Word : Congress , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "==========================================\n",
      "Word : members , type : NNS ,  means : noun, plural\n",
      "==========================================\n",
      "Word : of , type : IN ,  means : conjunction, subordinating or preposition\n",
      "==========================================\n",
      "Word : the , type : DT ,  means : determiner\n",
      "==========================================\n",
      "Word : Supreme , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : Court , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : and , type : CC ,  means : conjunction, coordinating\n",
      "==========================================\n",
      "Word : diplomatic , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "==========================================\n",
      "Word : corps , type : NN ,  means : noun, singular or mass\n",
      "==========================================\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "==========================================\n",
      "Word : distinguished , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "==========================================\n",
      "Word : guests , type : NNS ,  means : noun, plural\n",
      "==========================================\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "==========================================\n",
      "Word : and , type : CC ,  means : conjunction, coordinating\n",
      "==========================================\n",
      "Word : fellow , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "==========================================\n",
      "Word : citizens , type : NNS ,  means : noun, plural\n",
      "==========================================\n",
      "Word : : , type : : ,  means : punctuation mark, colon or ellipsis\n",
      "==========================================\n",
      "Word : Today , type : VB ,  means : verb, base form\n",
      "==========================================\n",
      "Word : our , type : PRP$ ,  means : pronoun, possessive\n",
      "==========================================\n",
      "Word : nation , type : NN ,  means : noun, singular or mass\n",
      "==========================================\n",
      "Word : lost , type : VBD ,  means : verb, past tense\n",
      "==========================================\n",
      "Word : a , type : DT ,  means : determiner\n",
      "==========================================\n",
      "Word : beloved , type : VBN ,  means : verb, past participle\n",
      "==========================================\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "==========================================\n",
      "Word : graceful , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "==========================================\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "==========================================\n",
      "Word : courageous , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "==========================================\n",
      "Word : woman , type : NN ,  means : noun, singular or mass\n",
      "==========================================\n",
      "Word : who , type : WP ,  means : wh-pronoun, personal\n",
      "==========================================\n",
      "Word : called , type : VBD ,  means : verb, past tense\n",
      "==========================================\n",
      "Word : America , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : to , type : TO ,  means : infinitival \"to\"\n",
      "==========================================\n",
      "Word : its , type : PRP$ ,  means : pronoun, possessive\n",
      "==========================================\n",
      "Word : founding , type : NN ,  means : noun, singular or mass\n",
      "==========================================\n",
      "Word : ideals , type : NNS ,  means : noun, plural\n",
      "==========================================\n",
      "Word : and , type : CC ,  means : conjunction, coordinating\n",
      "==========================================\n",
      "Word : carried , type : VBD ,  means : verb, past tense\n",
      "==========================================\n",
      "Word : on , type : IN ,  means : conjunction, subordinating or preposition\n",
      "==========================================\n",
      "Word : a , type : DT ,  means : determiner\n",
      "==========================================\n",
      "Word : noble , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "==========================================\n",
      "Word : dream , type : NN ,  means : noun, singular or mass\n",
      "==========================================\n",
      "Word : . , type : . ,  means : punctuation mark, sentence closer\n",
      "==========================================\n",
      "Word : Tonight , type : NN ,  means : noun, singular or mass\n",
      "==========================================\n",
      "Word : we , type : PRP ,  means : pronoun, personal\n",
      "==========================================\n",
      "Word : are , type : VBP ,  means : verb, non-3rd person singular present\n",
      "==========================================\n",
      "Word : comforted , type : VBN ,  means : verb, past participle\n",
      "==========================================\n",
      "Word : by , type : IN ,  means : conjunction, subordinating or preposition\n",
      "==========================================\n",
      "Word : the , type : DT ,  means : determiner\n",
      "==========================================\n",
      "Word : hope , type : NN ,  means : noun, singular or mass\n",
      "==========================================\n",
      "Word : of , type : IN ,  means : conjunction, subordinating or preposition\n",
      "==========================================\n",
      "Word : a , type : DT ,  means : determiner\n",
      "==========================================\n",
      "Word : glad , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "==========================================\n",
      "Word : reunion , type : NN ,  means : noun, singular or mass\n",
      "==========================================\n",
      "Word : with , type : IN ,  means : conjunction, subordinating or preposition\n",
      "==========================================\n",
      "Word : the , type : DT ,  means : determiner\n",
      "==========================================\n",
      "Word : husband , type : NN ,  means : noun, singular or mass\n",
      "==========================================\n",
      "Word : who , type : WP ,  means : wh-pronoun, personal\n",
      "==========================================\n",
      "Word : was , type : VBD ,  means : verb, past tense\n",
      "==========================================\n",
      "Word : taken , type : VBN ,  means : verb, past participle\n",
      "==========================================\n",
      "Word : so , type : RB ,  means : adverb\n",
      "==========================================\n",
      "Word : long , type : RB ,  means : adverb\n",
      "==========================================\n",
      "Word : ago , type : RB ,  means : adverb\n",
      "==========================================\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "==========================================\n",
      "Word : and , type : CC ,  means : conjunction, coordinating\n",
      "==========================================\n",
      "Word : we , type : PRP ,  means : pronoun, personal\n",
      "==========================================\n",
      "Word : are , type : VBP ,  means : verb, non-3rd person singular present\n",
      "==========================================\n",
      "Word : grateful , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "==========================================\n",
      "Word : for , type : IN ,  means : conjunction, subordinating or preposition\n",
      "==========================================\n",
      "Word : the , type : DT ,  means : determiner\n",
      "==========================================\n",
      "Word : good , type : JJ ,  means : adjective (English), other noun-modifier (Chinese)\n",
      "==========================================\n",
      "Word : life , type : NN ,  means : noun, singular or mass\n",
      "==========================================\n",
      "Word : of , type : IN ,  means : conjunction, subordinating or preposition\n",
      "==========================================\n",
      "Word : Coretta , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : Scott , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : King , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : . , type : . ,  means : punctuation mark, sentence closer\n",
      "==========================================\n",
      "Word : ( , type : ( ,  means : None\n",
      "==========================================\n",
      "Word : Applause , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : . , type : . ,  means : punctuation mark, sentence closer\n",
      "==========================================\n",
      "Word : ) , type : ) ,  means : None\n",
      "==========================================\n",
      "Word : President , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : George , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : W. , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : Bush , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : reacts , type : VBZ ,  means : verb, 3rd person singular present\n",
      "==========================================\n",
      "Word : to , type : TO ,  means : infinitival \"to\"\n",
      "==========================================\n",
      "Word : applause , type : VB ,  means : verb, base form\n",
      "==========================================\n",
      "Word : during , type : IN ,  means : conjunction, subordinating or preposition\n",
      "==========================================\n",
      "Word : his , type : PRP$ ,  means : pronoun, possessive\n",
      "==========================================\n",
      "Word : State , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : of , type : IN ,  means : conjunction, subordinating or preposition\n",
      "==========================================\n",
      "Word : the , type : DT ,  means : determiner\n",
      "==========================================\n",
      "Word : Union , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : Address , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : at , type : IN ,  means : conjunction, subordinating or preposition\n",
      "==========================================\n",
      "Word : the , type : DT ,  means : determiner\n",
      "==========================================\n",
      "Word : Capitol , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "==========================================\n",
      "Word : Tuesday , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : , , type : , ,  means : punctuation mark, comma\n",
      "==========================================\n",
      "Word : Jan , type : NNP ,  means : noun, proper singular\n",
      "==========================================\n",
      "Word : . , type : . ,  means : punctuation mark, sentence closer\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yousef_haroon\\anaconda3\\Lib\\site-packages\\spacy\\glossary.py:20: UserWarning: [W118] Term '(' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "C:\\Users\\yousef_haroon\\anaconda3\\Lib\\site-packages\\spacy\\glossary.py:20: UserWarning: [W118] Term ')' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n"
     ]
    }
   ],
   "source": [
    "tokenizer=PunktSentenceTokenizer(train_text)\n",
    "tokenized=tokenizer.tokenize(sample_text)\n",
    "for i in tokenized[:5]:\n",
    "    for w,m in nltk.pos_tag(nltk.word_tokenize(i)):\n",
    "        print(f'Word : {w} , type : {m} ,  means : {spacy.explain(m)}')\n",
    "        print(\"==========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c0f8309-7f4e-4e87-bf7c-b39cfe2aa61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "p_stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f94502de-6922-48b2-8fa9-9d5d3f040153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run       run\n",
      "runner    runner\n",
      "running   run\n",
      "ran       ran\n",
      "runs      run\n",
      "easily    easili\n",
      "fairly    fairli\n"
     ]
    }
   ],
   "source": [
    "words=['run','runner','running','ran','runs','easily','fairly']\n",
    "for word in words:\n",
    "    print(f\"{word :{9}} {p_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f26c77-6bd7-4583-826e-e35a1cc3710c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run       run\n",
      "runner    runner\n",
      "running   run\n",
      "ran       ran\n",
      "runs      run\n",
      "easily    easili\n",
      "fairly    fair\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "s_stemmer=SnowballStemmer(language='english')\n",
    "for word in words:\n",
    "    print(f\"{word :{9}} {s_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "507eabb1-7879-4510-88f0-cf5506143444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import  PorterStemmer , LancasterStemmer\n",
    "from nltk.tokenize import sent_tokenize , word_tokenize\n",
    "ps=PorterStemmer()\n",
    "ls=LancasterStemmer()\n",
    "words=['is','was','be','been','are','were','being']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98666648-7169-4284-93ca-bf9cdb1d3077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n",
      "is\n",
      "====================================\n",
      "wa\n",
      "was\n",
      "====================================\n",
      "be\n",
      "be\n",
      "====================================\n",
      "been\n",
      "been\n",
      "====================================\n",
      "are\n",
      "ar\n",
      "====================================\n",
      "were\n",
      "wer\n",
      "====================================\n",
      "be\n",
      "being\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(ps.stem(word))\n",
    "    print(ls.stem(word))\n",
    "    print('====================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4c676c-b253-41c1-b60b-452f73e0fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "had\n",
      "you\n",
      "book\n",
      "the\n",
      "air\n",
      "bool\n",
      "yet\n",
      "?\n",
      "if\n",
      "not\n",
      "tri\n",
      "to\n",
      "book\n",
      "it\n",
      "asap\n",
      "sinc\n",
      "book\n",
      "will\n",
      "beout\n",
      "of\n",
      "book\n"
     ]
    }
   ],
   "source": [
    "sentence='had you booked the air booling yet ? if not try to book it ASAP since booking will beout of books'\n",
    "words=word_tokenize(sentence)\n",
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e809d27-e05f-4f67-93e3-18b676e53ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word                porter stemmer      lncaster stemmer    \n",
      "----------------------------------------------------\n",
      "had                 had                 had                 \n",
      "you                 you                 you                 \n",
      "booked              book                book                \n",
      "the                 the                 the                 \n",
      "air                 air                 air                 \n",
      "booling             bool                bool                \n",
      "yet                 yet                 yet                 \n",
      "?                   ?                   ?                   \n",
      "if                  if                  if                  \n",
      "not                 not                 not                 \n",
      "try                 tri                 try                 \n",
      "to                  to                  to                  \n",
      "book                book                book                \n",
      "it                  it                  it                  \n",
      "ASAP                asap                asap                \n",
      "since               sinc                sint                \n",
      "booking             book                book                \n",
      "will                will                wil                 \n",
      "beout               beout               beout               \n",
      "of                  of                  of                  \n",
      "books               book                book                \n"
     ]
    }
   ],
   "source": [
    "print(\"{0:20}{1:20}{2:20}\".format(\"word\",\"porter stemmer\",\"lncaster stemmer\"))\n",
    "print('----------------------------------------------------')\n",
    "for w in words:\n",
    "    print(\"{0:20}{1:20}{2:20}\".format(w,ps.stem(w),ls.stem(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9983232-5f22-4499-b367-0cb91177da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "def show_lemma(text):\n",
    "    for token in text:\n",
    "        print(f\"{token.text:{15}} {token.pos_:{15}} {token.lemma:{25}} {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f0cdadf-a1de-4388-b3b0-1d498e633454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I               PRON                  4690420944186131903 I\n",
      "saw             VERB                 11925638236994514241 see\n",
      "eighteen        NUM                   9609336664675087640 eighteen\n",
      "mice            NOUN                  1384165645700560590 mouse\n",
      "today           NOUN                 11042482332948150395 today\n",
      "!               PUNCT                17494803046312582752 !\n"
     ]
    }
   ],
   "source": [
    "doc2=nlp(\"I saw eighteen mice today !\")\n",
    "show_lemma(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5de09e4d-2eff-4a19-a18b-1903ea467bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats           cat\n",
      "cacti          cactus\n",
      "radii          radius\n",
      "feet           foot\n",
      "speech         speech\n",
      "runner         runner\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "words=['cats','cacti','radii','feet','speech','runner']\n",
    "for w in words:\n",
    "    print(f\"{w:{15}}{lemmatizer.lemmatize(w)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e7a30cd-b05e-497a-993b-e24ac33b7130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meet\n",
      "meeting\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"meeting\",'v'))\n",
    "print(lemmatizer.lemmatize(\"meeting\",'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bb29862-b3d0-48f8-8b6d-bcd31d760ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He             He\n",
      "was            wa\n",
      "running        running\n",
      "and            and\n",
      "eating         eating\n",
      "at             at\n",
      "same           same\n",
      "He             He\n",
      "has            ha\n",
      "bad            bad\n",
      "habit          habit\n",
      "of             of\n",
      "swimming       swimming\n",
      "after          after\n",
      "playing        playing\n",
      "long           long\n",
      "hours          hour\n",
      "in             in\n",
      "the            the\n",
      "sun            sun\n"
     ]
    }
   ],
   "source": [
    "sentence=\"He was running and eating at same . He has bad habit of swimming after playing long hours in the sun.\"\n",
    "panctuation='?!:.,;'\n",
    "sentence_words=word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in panctuation:\n",
    "        sentence_words.remove(word)\n",
    "for w in sentence_words:\n",
    "    print(f\"{w:{15}}{lemmatizer.lemmatize(w)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1b68adc-2625-4ab7-8c2f-7d074dd6020d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He             He\n",
      "was            be\n",
      "running        run\n",
      "and            and\n",
      "eating         eat\n",
      "at             at\n",
      "same           same\n",
      "He             He\n",
      "has            have\n",
      "bad            bad\n",
      "habit          habit\n",
      "of             of\n",
      "swimming       swim\n",
      "after          after\n",
      "playing        play\n",
      "long           long\n",
      "hours          hours\n",
      "in             in\n",
      "the            the\n",
      "sun            sun\n"
     ]
    }
   ],
   "source": [
    "for w in sentence_words:\n",
    "    print(f\"{w:{15}}{lemmatizer.lemmatize(w,'v')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80887748-4863-4933-a4f5-a19aa721e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "601771fa-424d-40bf-9cde-c8e8b004f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(\"Apple to build a hong kong factory for $6 million\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37b4708b-c1bf-46f7-984f-8d937af6ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple|to|build|a|hong|kong|factory|for|$|6|million|"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,end='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5da0ac3-9be9-4350-8a2e-ad869f381a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple      ORG        Companies, agencies, institutions, etc.\n",
      "hong kong  GPE        Countries, cities, states\n",
      "$6 million MONEY      Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "for token in doc.ents:\n",
    "    print(f\"{token.text:{10}} {token.label_:{10}} {spacy.explain(token.label_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de738770-23b8-4be9-ad18-416b7dbab3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "383\n",
      "ORG\n",
      "Companies, agencies, institutions, etc.\n",
      "0\n",
      "1\n",
      "0\n",
      "5\n",
      "-----------------------------------------\n",
      "hong kong\n",
      "384\n",
      "GPE\n",
      "Countries, cities, states\n",
      "4\n",
      "6\n",
      "17\n",
      "26\n",
      "-----------------------------------------\n",
      "$6 million\n",
      "394\n",
      "MONEY\n",
      "Monetary values, including unit\n",
      "8\n",
      "11\n",
      "39\n",
      "49\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text)\n",
    "    print(ent.label)\n",
    "    print(ent.label_)\n",
    "    print(spacy.explain(ent.label_))\n",
    "    print(ent.start)\n",
    "    print(ent.end)\n",
    "    print(ent.start_char)\n",
    "    print(ent.end_char)\n",
    "    print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a61a954-8eac-477b-a162-55e14fdf6b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPRO       ORG        Companies, agencies, institutions, etc.\n",
      "U.K.       GPE        Countries, cities, states\n",
      "$6 million MONEY      Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "doc=nlp(\"CPRO to build a U.K. factory for $6 million\")\n",
    "\n",
    "ORG=doc.vocab.strings['ORG']\n",
    "new_ent=Span(doc,0,1,label=ORG)\n",
    "\n",
    "doc.ents=list(doc.ents) + [new_ent]\n",
    "\n",
    "for token in doc.ents:\n",
    "    print(f\"{token.text:{10}} {token.label_:{10}} {spacy.explain(token.label_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a0728b4-587d-402d-a647-e2e40a6c45b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars\n",
      "cars\n",
      "nominal subject\n",
      "3342607623747562680\n",
      "NP\n",
      "noun phrase\n",
      "0\n",
      "2\n",
      "0\n",
      "15\n",
      "------------------------------\n",
      "insurance liability\n",
      "liability\n",
      "direct object\n",
      "3342607623747562680\n",
      "NP\n",
      "noun phrase\n",
      "3\n",
      "5\n",
      "22\n",
      "41\n",
      "------------------------------\n",
      "manufaturers\n",
      "manufaturers\n",
      "object of preposition\n",
      "3342607623747562680\n",
      "NP\n",
      "noun phrase\n",
      "6\n",
      "7\n",
      "49\n",
      "61\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "doc2=nlp(\"Autonomous cars shift insurance liability toward manufaturers.\")\n",
    "for chunk in doc2.noun_chunks:\n",
    "    print(chunk.text)\n",
    "    print(chunk.root.text)\n",
    "    print(spacy.explain(chunk.root.dep_))\n",
    "    print(chunk.label)\n",
    "    print(chunk.label_)\n",
    "    print(spacy.explain(chunk.label_))\n",
    "    print(chunk.start)\n",
    "    print(chunk.end)\n",
    "    print(chunk.start_char)\n",
    "    print(chunk.end_char)\n",
    "    print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba516566-ecab-4316-b0f0-86b45de1f58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "nlp.vocab['have'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c1f77d0-1723-43ed-bf42-93dbea2f23ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['it'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "378e2608-928f-4a79-a886-14ce12fd8daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['park'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f021191-67de-42db-b3be-6ae8ef57cee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'btw',\n",
       " 'but',\n",
       " 'by',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'could',\n",
       " 'did',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'done',\n",
       " 'down',\n",
       " 'due',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'except',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forty',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'indeed',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'last',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meanwhile',\n",
       " 'might',\n",
       " 'mine',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " \"n't\",\n",
       " 'name',\n",
       " 'namely',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'n‘t',\n",
       " 'n’t',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'part',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'please',\n",
       " 'put',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 're',\n",
       " 'really',\n",
       " 'regarding',\n",
       " 'same',\n",
       " 'say',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'side',\n",
       " 'since',\n",
       " 'six',\n",
       " 'sixty',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhere',\n",
       " 'still',\n",
       " 'such',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'two',\n",
       " 'under',\n",
       " 'unless',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'was',\n",
       " 'we',\n",
       " 'well',\n",
       " 'were',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " '‘d',\n",
       " '‘ll',\n",
       " '‘m',\n",
       " '‘re',\n",
       " '‘s',\n",
       " '‘ve',\n",
       " '’d',\n",
       " '’ll',\n",
       " '’m',\n",
       " '’re',\n",
       " '’s',\n",
       " '’ve'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a120e86-dcc5-4a6a-a113-75000628d5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(nlp.vocab['btw'].is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce886b78-704e-4861-a5ba-dbd717407786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "nlp.Defaults.stop_words.add('btw')\n",
    "nlp.vocab['btw'].is_stop=True\n",
    "print(nlp.vocab['btw'].is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0225e71e-0929-4e75-b43f-61bca9a1da51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(nlp.vocab['beyond'].is_stop)\n",
    "nlp.Defaults.stop_words.remove('beyond')\n",
    "nlp.vocab['beyond'].is_stop=False\n",
    "print(nlp.vocab['beyond'].is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f350d59c-3b4c-4579-b2fd-3e9e04357aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yousef_haroon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b24fd4eb-4912-40dc-b76c-b9524c9027a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words=set(stopwords.words('english'))\n",
    "print(len(stop_words))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90113eaa-59f8-4bf1-a974-94b9aa2e975e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'sample',\n",
       " 'sentence',\n",
       " ',',\n",
       " 'And',\n",
       " 'this',\n",
       " 'showing',\n",
       " 'off',\n",
       " 'the',\n",
       " 'stop',\n",
       " 'words',\n",
       " 'filtration',\n",
       " '.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example=\"this is sample sentence, And this showing off the stop words filtration.\"\n",
    "word_tokens=word_tokenize(example)\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fad5837f-0bb0-4725-b60d-d73de58d765b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample', 'sentence', ',', 'And', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "filtered_sentence=[w for w in word_tokens if not w in stop_words]\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bddbad47-8754-4841-a421-3726eb22bd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754\n",
      "['إذ', 'إذا', 'إذما', 'إذن', 'أف', 'أقل', 'أكثر', 'ألا', 'إلا', 'التي', 'الذي', 'الذين', 'اللاتي', 'اللائي', 'اللتان', 'اللتيا', 'اللتين', 'اللذان', 'اللذين', 'اللواتي', 'إلى', 'إليك', 'إليكم', 'إليكما', 'إليكن', 'أم', 'أما', 'أما', 'إما', 'أن', 'إن', 'إنا', 'أنا', 'أنت', 'أنتم', 'أنتما', 'أنتن', 'إنما', 'إنه', 'أنى', 'أنى', 'آه', 'آها', 'أو', 'أولاء', 'أولئك', 'أوه', 'آي', 'أي', 'أيها', 'إي', 'أين', 'أين', 'أينما', 'إيه', 'بخ', 'بس', 'بعد', 'بعض', 'بك', 'بكم', 'بكم', 'بكما', 'بكن', 'بل', 'بلى', 'بما', 'بماذا', 'بمن', 'بنا', 'به', 'بها', 'بهم', 'بهما', 'بهن', 'بي', 'بين', 'بيد', 'تلك', 'تلكم', 'تلكما', 'ته', 'تي', 'تين', 'تينك', 'ثم', 'ثمة', 'حاشا', 'حبذا', 'حتى', 'حيث', 'حيثما', 'حين', 'خلا', 'دون', 'ذا', 'ذات', 'ذاك', 'ذان', 'ذانك', 'ذلك', 'ذلكم', 'ذلكما', 'ذلكن', 'ذه', 'ذو', 'ذوا', 'ذواتا', 'ذواتي', 'ذي', 'ذين', 'ذينك', 'ريث', 'سوف', 'سوى', 'شتان', 'عدا', 'عسى', 'عل', 'على', 'عليك', 'عليه', 'عما', 'عن', 'عند', 'غير', 'فإذا', 'فإن', 'فلا', 'فمن', 'في', 'فيم', 'فيما', 'فيه', 'فيها', 'قد', 'كأن', 'كأنما', 'كأي', 'كأين', 'كذا', 'كذلك', 'كل', 'كلا', 'كلاهما', 'كلتا', 'كلما', 'كليكما', 'كليهما', 'كم', 'كم', 'كما', 'كي', 'كيت', 'كيف', 'كيفما', 'لا', 'لاسيما', 'لدى', 'لست', 'لستم', 'لستما', 'لستن', 'لسن', 'لسنا', 'لعل', 'لك', 'لكم', 'لكما', 'لكن', 'لكنما', 'لكي', 'لكيلا', 'لم', 'لما', 'لن', 'لنا', 'له', 'لها', 'لهم', 'لهما', 'لهن', 'لو', 'لولا', 'لوما', 'لي', 'لئن', 'ليت', 'ليس', 'ليسا', 'ليست', 'ليستا', 'ليسوا', 'ما', 'ماذا', 'متى', 'مذ', 'مع', 'مما', 'ممن', 'من', 'منه', 'منها', 'منذ', 'مه', 'مهما', 'نحن', 'نحو', 'نعم', 'ها', 'هاتان', 'هاته', 'هاتي', 'هاتين', 'هاك', 'هاهنا', 'هذا', 'هذان', 'هذه', 'هذي', 'هذين', 'هكذا', 'هل', 'هلا', 'هم', 'هما', 'هن', 'هنا', 'هناك', 'هنالك', 'هو', 'هؤلاء', 'هي', 'هيا', 'هيت', 'هيهات', 'والذي', 'والذين', 'وإذ', 'وإذا', 'وإن', 'ولا', 'ولكن', 'ولو', 'وما', 'ومن', 'وهو', 'يا', 'أبٌ', 'أخٌ', 'حمٌ', 'فو', 'أنتِ', 'يناير', 'فبراير', 'مارس', 'أبريل', 'مايو', 'يونيو', 'يوليو', 'أغسطس', 'سبتمبر', 'أكتوبر', 'نوفمبر', 'ديسمبر', 'جانفي', 'فيفري', 'مارس', 'أفريل', 'ماي', 'جوان', 'جويلية', 'أوت', 'كانون', 'شباط', 'آذار', 'نيسان', 'أيار', 'حزيران', 'تموز', 'آب', 'أيلول', 'تشرين', 'دولار', 'دينار', 'ريال', 'درهم', 'ليرة', 'جنيه', 'قرش', 'مليم', 'فلس', 'هللة', 'سنتيم', 'يورو', 'ين', 'يوان', 'شيكل', 'واحد', 'اثنان', 'ثلاثة', 'أربعة', 'خمسة', 'ستة', 'سبعة', 'ثمانية', 'تسعة', 'عشرة', 'أحد', 'اثنا', 'اثني', 'إحدى', 'ثلاث', 'أربع', 'خمس', 'ست', 'سبع', 'ثماني', 'تسع', 'عشر', 'ثمان', 'سبت', 'أحد', 'اثنين', 'ثلاثاء', 'أربعاء', 'خميس', 'جمعة', 'أول', 'ثان', 'ثاني', 'ثالث', 'رابع', 'خامس', 'سادس', 'سابع', 'ثامن', 'تاسع', 'عاشر', 'حادي', 'أ', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ي', 'ء', 'ى', 'آ', 'ؤ', 'ئ', 'أ', 'ة', 'ألف', 'باء', 'تاء', 'ثاء', 'جيم', 'حاء', 'خاء', 'دال', 'ذال', 'راء', 'زاي', 'سين', 'شين', 'صاد', 'ضاد', 'طاء', 'ظاء', 'عين', 'غين', 'فاء', 'قاف', 'كاف', 'لام', 'ميم', 'نون', 'هاء', 'واو', 'ياء', 'همزة', 'ي', 'نا', 'ك', 'كن', 'ه', 'إياه', 'إياها', 'إياهما', 'إياهم', 'إياهن', 'إياك', 'إياكما', 'إياكم', 'إياك', 'إياكن', 'إياي', 'إيانا', 'أولالك', 'تانِ', 'تانِك', 'تِه', 'تِي', 'تَيْنِ', 'ثمّ', 'ثمّة', 'ذانِ', 'ذِه', 'ذِي', 'ذَيْنِ', 'هَؤلاء', 'هَاتانِ', 'هَاتِه', 'هَاتِي', 'هَاتَيْنِ', 'هَذا', 'هَذانِ', 'هَذِه', 'هَذِي', 'هَذَيْنِ', 'الألى', 'الألاء', 'أل', 'أنّى', 'أيّ', 'ّأيّان', 'أنّى', 'أيّ', 'ّأيّان', 'ذيت', 'كأيّ', 'كأيّن', 'بضع', 'فلان', 'وا', 'آمينَ', 'آهِ', 'آهٍ', 'آهاً', 'أُفٍّ', 'أُفٍّ', 'أفٍّ', 'أمامك', 'أمامكَ', 'أوّهْ', 'إلَيْكَ', 'إلَيْكَ', 'إليكَ', 'إليكنّ', 'إيهٍ', 'بخٍ', 'بسّ', 'بَسْ', 'بطآن', 'بَلْهَ', 'حاي', 'حَذارِ', 'حيَّ', 'حيَّ', 'دونك', 'رويدك', 'سرعان', 'شتانَ', 'شَتَّانَ', 'صهْ', 'صهٍ', 'طاق', 'طَق', 'عَدَسْ', 'كِخ', 'مكانَك', 'مكانَك', 'مكانَك', 'مكانكم', 'مكانكما', 'مكانكنّ', 'نَخْ', 'هاكَ', 'هَجْ', 'هلم', 'هيّا', 'هَيْهات', 'وا', 'واهاً', 'وراءَك', 'وُشْكَانَ', 'وَيْ', 'يفعلان', 'تفعلان', 'يفعلون', 'تفعلون', 'تفعلين', 'اتخذ', 'ألفى', 'تخذ', 'ترك', 'تعلَّم', 'جعل', 'حجا', 'حبيب', 'خال', 'حسب', 'خال', 'درى', 'رأى', 'زعم', 'صبر', 'ظنَّ', 'عدَّ', 'علم', 'غادر', 'ذهب', 'وجد', 'ورد', 'وهب', 'أسكن', 'أطعم', 'أعطى', 'رزق', 'زود', 'سقى', 'كسا', 'أخبر', 'أرى', 'أعلم', 'أنبأ', 'حدَث', 'خبَّر', 'نبَّا', 'أفعل به', 'ما أفعله', 'بئس', 'ساء', 'طالما', 'قلما', 'لات', 'لكنَّ', 'ءَ', 'أجل', 'إذاً', 'أمّا', 'إمّا', 'إنَّ', 'أنًّ', 'أى', 'إى', 'أيا', 'ب', 'ثمَّ', 'جلل', 'جير', 'رُبَّ', 'س', 'علًّ', 'ف', 'كأنّ', 'كلَّا', 'كى', 'ل', 'لات', 'لعلَّ', 'لكنَّ', 'لكنَّ', 'م', 'نَّ', 'هلّا', 'وا', 'أل', 'إلّا', 'ت', 'ك', 'لمّا', 'ن', 'ه', 'و', 'ا', 'ي', 'تجاه', 'تلقاء', 'جميع', 'حسب', 'سبحان', 'شبه', 'لعمر', 'مثل', 'معاذ', 'أبو', 'أخو', 'حمو', 'فو', 'مئة', 'مئتان', 'ثلاثمئة', 'أربعمئة', 'خمسمئة', 'ستمئة', 'سبعمئة', 'ثمنمئة', 'تسعمئة', 'مائة', 'ثلاثمائة', 'أربعمائة', 'خمسمائة', 'ستمائة', 'سبعمائة', 'ثمانمئة', 'تسعمائة', 'عشرون', 'ثلاثون', 'اربعون', 'خمسون', 'ستون', 'سبعون', 'ثمانون', 'تسعون', 'عشرين', 'ثلاثين', 'اربعين', 'خمسين', 'ستين', 'سبعين', 'ثمانين', 'تسعين', 'بضع', 'نيف', 'أجمع', 'جميع', 'عامة', 'عين', 'نفس', 'لا سيما', 'أصلا', 'أهلا', 'أيضا', 'بؤسا', 'بعدا', 'بغتة', 'تعسا', 'حقا', 'حمدا', 'خلافا', 'خاصة', 'دواليك', 'سحقا', 'سرا', 'سمعا', 'صبرا', 'صدقا', 'صراحة', 'طرا', 'عجبا', 'عيانا', 'غالبا', 'فرادى', 'فضلا', 'قاطبة', 'كثيرا', 'لبيك', 'معاذ', 'أبدا', 'إزاء', 'أصلا', 'الآن', 'أمد', 'أمس', 'آنفا', 'آناء', 'أنّى', 'أول', 'أيّان', 'تارة', 'ثمّ', 'ثمّة', 'حقا', 'صباح', 'مساء', 'ضحوة', 'عوض', 'غدا', 'غداة', 'قطّ', 'كلّما', 'لدن', 'لمّا', 'مرّة', 'قبل', 'خلف', 'أمام', 'فوق', 'تحت', 'يمين', 'شمال', 'ارتدّ', 'استحال', 'أصبح', 'أضحى', 'آض', 'أمسى', 'انقلب', 'بات', 'تبدّل', 'تحوّل', 'حار', 'رجع', 'راح', 'صار', 'ظلّ', 'عاد', 'غدا', 'كان', 'ما انفك', 'ما برح', 'مادام', 'مازال', 'مافتئ', 'ابتدأ', 'أخذ', 'اخلولق', 'أقبل', 'انبرى', 'أنشأ', 'أوشك', 'جعل', 'حرى', 'شرع', 'طفق', 'علق', 'قام', 'كرب', 'كاد', 'هبّ']\n"
     ]
    }
   ],
   "source": [
    "ar_sw=nltk.corpus.stopwords.words(\"arabic\")\n",
    "print(len(ar_sw))\n",
    "print(ar_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5bea2118-663e-49a9-8483-08f854ea909a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754\n",
      "['إذ', 'إذا', 'إذما', 'إذن', 'أف', 'أقل', 'أكثر', 'ألا', 'إلا', 'التي', 'الذي', 'الذين', 'اللاتي', 'اللائي', 'اللتان', 'اللتيا', 'اللتين', 'اللذان', 'اللذين', 'اللواتي', 'إلى', 'إليك', 'إليكم', 'إليكما', 'إليكن', 'أم', 'أما', 'أما', 'إما', 'أن', 'إن', 'إنا', 'أنا', 'أنت', 'أنتم', 'أنتما', 'أنتن', 'إنما', 'إنه', 'أنى', 'أنى', 'آه', 'آها', 'أو', 'أولاء', 'أولئك', 'أوه', 'آي', 'أي', 'أيها', 'إي', 'أين', 'أين', 'أينما', 'إيه', 'بخ', 'بس', 'بعد', 'بعض', 'بك', 'بكم', 'بكم', 'بكما', 'بكن', 'بل', 'بلى', 'بما', 'بماذا', 'بمن', 'بنا', 'به', 'بها', 'بهم', 'بهما', 'بهن', 'بي', 'بين', 'بيد', 'تلك', 'تلكم', 'تلكما', 'ته', 'تي', 'تين', 'تينك', 'ثم', 'ثمة', 'حاشا', 'حبذا', 'حتى', 'حيث', 'حيثما', 'حين', 'خلا', 'دون', 'ذا', 'ذات', 'ذاك', 'ذان', 'ذانك', 'ذلك', 'ذلكم', 'ذلكما', 'ذلكن', 'ذه', 'ذو', 'ذوا', 'ذواتا', 'ذواتي', 'ذي', 'ذين', 'ذينك', 'ريث', 'سوف', 'سوى', 'شتان', 'عدا', 'عسى', 'عل', 'على', 'عليك', 'عليه', 'عما', 'عن', 'عند', 'غير', 'فإذا', 'فإن', 'فلا', 'فمن', 'في', 'فيم', 'فيما', 'فيه', 'فيها', 'قد', 'كأن', 'كأنما', 'كأي', 'كأين', 'كذا', 'كذلك', 'كل', 'كلا', 'كلاهما', 'كلتا', 'كلما', 'كليكما', 'كليهما', 'كم', 'كم', 'كما', 'كي', 'كيت', 'كيف', 'كيفما', 'لا', 'لاسيما', 'لدى', 'لست', 'لستم', 'لستما', 'لستن', 'لسن', 'لسنا', 'لعل', 'لك', 'لكم', 'لكما', 'لكن', 'لكنما', 'لكي', 'لكيلا', 'لم', 'لما', 'لن', 'لنا', 'له', 'لها', 'لهم', 'لهما', 'لهن', 'لو', 'لولا', 'لوما', 'لي', 'لئن', 'ليت', 'ليس', 'ليسا', 'ليست', 'ليستا', 'ليسوا', 'ما', 'ماذا', 'متى', 'مذ', 'مع', 'مما', 'ممن', 'من', 'منه', 'منها', 'منذ', 'مه', 'مهما', 'نحن', 'نحو', 'نعم', 'ها', 'هاتان', 'هاته', 'هاتي', 'هاتين', 'هاك', 'هاهنا', 'هذا', 'هذان', 'هذه', 'هذي', 'هذين', 'هكذا', 'هل', 'هلا', 'هم', 'هما', 'هن', 'هنا', 'هناك', 'هنالك', 'هو', 'هؤلاء', 'هي', 'هيا', 'هيت', 'هيهات', 'والذي', 'والذين', 'وإذ', 'وإذا', 'وإن', 'ولا', 'ولكن', 'ولو', 'وما', 'ومن', 'وهو', 'يا', 'أبٌ', 'أخٌ', 'حمٌ', 'فو', 'أنتِ', 'يناير', 'فبراير', 'مارس', 'أبريل', 'مايو', 'يونيو', 'يوليو', 'أغسطس', 'سبتمبر', 'أكتوبر', 'نوفمبر', 'ديسمبر', 'جانفي', 'فيفري', 'مارس', 'أفريل', 'ماي', 'جوان', 'جويلية', 'أوت', 'كانون', 'شباط', 'آذار', 'نيسان', 'أيار', 'حزيران', 'تموز', 'آب', 'أيلول', 'تشرين', 'دولار', 'دينار', 'ريال', 'درهم', 'ليرة', 'جنيه', 'قرش', 'مليم', 'فلس', 'هللة', 'سنتيم', 'يورو', 'ين', 'يوان', 'شيكل', 'واحد', 'اثنان', 'ثلاثة', 'أربعة', 'خمسة', 'ستة', 'سبعة', 'ثمانية', 'تسعة', 'عشرة', 'أحد', 'اثنا', 'اثني', 'إحدى', 'ثلاث', 'أربع', 'خمس', 'ست', 'سبع', 'ثماني', 'تسع', 'عشر', 'ثمان', 'سبت', 'أحد', 'اثنين', 'ثلاثاء', 'أربعاء', 'خميس', 'جمعة', 'أول', 'ثان', 'ثاني', 'ثالث', 'رابع', 'خامس', 'سادس', 'سابع', 'ثامن', 'تاسع', 'عاشر', 'حادي', 'أ', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ي', 'ء', 'ى', 'آ', 'ؤ', 'ئ', 'أ', 'ة', 'ألف', 'باء', 'تاء', 'ثاء', 'جيم', 'حاء', 'خاء', 'دال', 'ذال', 'راء', 'زاي', 'سين', 'شين', 'صاد', 'ضاد', 'طاء', 'ظاء', 'عين', 'غين', 'فاء', 'قاف', 'كاف', 'لام', 'ميم', 'نون', 'هاء', 'واو', 'ياء', 'همزة', 'ي', 'نا', 'ك', 'كن', 'ه', 'إياه', 'إياها', 'إياهما', 'إياهم', 'إياهن', 'إياك', 'إياكما', 'إياكم', 'إياك', 'إياكن', 'إياي', 'إيانا', 'أولالك', 'تانِ', 'تانِك', 'تِه', 'تِي', 'تَيْنِ', 'ثمّ', 'ثمّة', 'ذانِ', 'ذِه', 'ذِي', 'ذَيْنِ', 'هَؤلاء', 'هَاتانِ', 'هَاتِه', 'هَاتِي', 'هَاتَيْنِ', 'هَذا', 'هَذانِ', 'هَذِه', 'هَذِي', 'هَذَيْنِ', 'الألى', 'الألاء', 'أل', 'أنّى', 'أيّ', 'ّأيّان', 'أنّى', 'أيّ', 'ّأيّان', 'ذيت', 'كأيّ', 'كأيّن', 'بضع', 'فلان', 'وا', 'آمينَ', 'آهِ', 'آهٍ', 'آهاً', 'أُفٍّ', 'أُفٍّ', 'أفٍّ', 'أمامك', 'أمامكَ', 'أوّهْ', 'إلَيْكَ', 'إلَيْكَ', 'إليكَ', 'إليكنّ', 'إيهٍ', 'بخٍ', 'بسّ', 'بَسْ', 'بطآن', 'بَلْهَ', 'حاي', 'حَذارِ', 'حيَّ', 'حيَّ', 'دونك', 'رويدك', 'سرعان', 'شتانَ', 'شَتَّانَ', 'صهْ', 'صهٍ', 'طاق', 'طَق', 'عَدَسْ', 'كِخ', 'مكانَك', 'مكانَك', 'مكانَك', 'مكانكم', 'مكانكما', 'مكانكنّ', 'نَخْ', 'هاكَ', 'هَجْ', 'هلم', 'هيّا', 'هَيْهات', 'وا', 'واهاً', 'وراءَك', 'وُشْكَانَ', 'وَيْ', 'يفعلان', 'تفعلان', 'يفعلون', 'تفعلون', 'تفعلين', 'اتخذ', 'ألفى', 'تخذ', 'ترك', 'تعلَّم', 'جعل', 'حجا', 'حبيب', 'خال', 'حسب', 'خال', 'درى', 'رأى', 'زعم', 'صبر', 'ظنَّ', 'عدَّ', 'علم', 'غادر', 'ذهب', 'وجد', 'ورد', 'وهب', 'أسكن', 'أطعم', 'أعطى', 'رزق', 'زود', 'سقى', 'كسا', 'أخبر', 'أرى', 'أعلم', 'أنبأ', 'حدَث', 'خبَّر', 'نبَّا', 'أفعل به', 'ما أفعله', 'بئس', 'ساء', 'طالما', 'قلما', 'لات', 'لكنَّ', 'ءَ', 'أجل', 'إذاً', 'أمّا', 'إمّا', 'إنَّ', 'أنًّ', 'أى', 'إى', 'أيا', 'ب', 'ثمَّ', 'جلل', 'جير', 'رُبَّ', 'س', 'علًّ', 'ف', 'كأنّ', 'كلَّا', 'كى', 'ل', 'لات', 'لعلَّ', 'لكنَّ', 'لكنَّ', 'م', 'نَّ', 'هلّا', 'وا', 'أل', 'إلّا', 'ت', 'ك', 'لمّا', 'ن', 'ه', 'و', 'ا', 'ي', 'تجاه', 'تلقاء', 'جميع', 'حسب', 'سبحان', 'شبه', 'لعمر', 'مثل', 'معاذ', 'أبو', 'أخو', 'حمو', 'فو', 'مئة', 'مئتان', 'ثلاثمئة', 'أربعمئة', 'خمسمئة', 'ستمئة', 'سبعمئة', 'ثمنمئة', 'تسعمئة', 'مائة', 'ثلاثمائة', 'أربعمائة', 'خمسمائة', 'ستمائة', 'سبعمائة', 'ثمانمئة', 'تسعمائة', 'عشرون', 'ثلاثون', 'اربعون', 'خمسون', 'ستون', 'سبعون', 'ثمانون', 'تسعون', 'عشرين', 'ثلاثين', 'اربعين', 'خمسين', 'ستين', 'سبعين', 'ثمانين', 'تسعين', 'بضع', 'نيف', 'أجمع', 'جميع', 'عامة', 'عين', 'نفس', 'لا سيما', 'أصلا', 'أهلا', 'أيضا', 'بؤسا', 'بعدا', 'بغتة', 'تعسا', 'حقا', 'حمدا', 'خلافا', 'خاصة', 'دواليك', 'سحقا', 'سرا', 'سمعا', 'صبرا', 'صدقا', 'صراحة', 'طرا', 'عجبا', 'عيانا', 'غالبا', 'فرادى', 'فضلا', 'قاطبة', 'كثيرا', 'لبيك', 'معاذ', 'أبدا', 'إزاء', 'أصلا', 'الآن', 'أمد', 'أمس', 'آنفا', 'آناء', 'أنّى', 'أول', 'أيّان', 'تارة', 'ثمّ', 'ثمّة', 'حقا', 'صباح', 'مساء', 'ضحوة', 'عوض', 'غدا', 'غداة', 'قطّ', 'كلّما', 'لدن', 'لمّا', 'مرّة', 'قبل', 'خلف', 'أمام', 'فوق', 'تحت', 'يمين', 'شمال', 'ارتدّ', 'استحال', 'أصبح', 'أضحى', 'آض', 'أمسى', 'انقلب', 'بات', 'تبدّل', 'تحوّل', 'حار', 'رجع', 'راح', 'صار', 'ظلّ', 'عاد', 'غدا', 'كان', 'ما انفك', 'ما برح', 'مادام', 'مازال', 'مافتئ', 'ابتدأ', 'أخذ', 'اخلولق', 'أقبل', 'انبرى', 'أنشأ', 'أوشك', 'جعل', 'حرى', 'شرع', 'طفق', 'علق', 'قام', 'كرب', 'كاد', 'هبّ']\n"
     ]
    }
   ],
   "source": [
    "ar_sw2=stopwords.words(\"arabic\")\n",
    "print(len(ar_sw2))\n",
    "print(ar_sw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57fac025-a416-4a7f-b250-9ffbf5c52448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement arabicstopwords (from versions: none)\n",
      "ERROR: No matching distribution found for arabicstopwords\n"
     ]
    }
   ],
   "source": [
    "pip install arabicstopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2eedaba-60ca-4a2c-b010-3547378c2be0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'arabicstopwords'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01marabicstopwords\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marabicstopwords\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'arabicstopwords'"
     ]
    }
   ],
   "source": [
    "import arabicstopwords.arabicstopwords as stp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c3c4fdd-b062-49cf-8ec5-e4de22678815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher=Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82541300-63d9-4fe9-bd83-37d9b99756f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1=[{'LOWER':'solarpower'}]\n",
    "pattern2=[{'LOWER':'solar'},{'LOWER':'power'}]\n",
    "pattern3=[{'LOWER':'solar'},{'IS_PUNCT':True},{'LOWER':'power'}]\n",
    "matcher.add(\"SolarPower\",[pattern1,pattern2,pattern3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f9292aa-61cc-428d-af4b-64d2f947f698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word id : 8656102463236116519 start at:0 end at:2 word is:Solar power\n",
      "word id : 8656102463236116519 start at:13 end at:16 word is:solar--power\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(\"\"\"Solar power, also known as solar electricity,\n",
    "           Almost half the solar--power installed in 2022\"\"\")\n",
    "found_matches=matcher(doc)\n",
    "for a,b,c in found_matches:\n",
    "    print(f'word id : {a} start at:{b} end at:{c} word is:{doc[b:c]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16eb432d-8162-4d8d-b4d3-5682e1669bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.remove('SolarPower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f5a56ca-f393-4511-ac88-03e22c32af68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word id : 8656102463236116519 start at:0 end at:2 word is:Solar power\n",
      "word id : 8656102463236116519 start at:13 end at:16 word is:solar--power\n"
     ]
    }
   ],
   "source": [
    "pattern1=[{'LOWER':'solarpower'}]\n",
    "pattern2=[{'LOWER':'solar'},{'IS_PUNCT':True,'OP':'*'},{'LOWER':'power'}]\n",
    "matcher.add(\"SolarPower\",[pattern1,pattern2])\n",
    "\n",
    "doc=nlp(\"\"\"Solar power, also known as solar electricity,\n",
    "           Almost half the solar--power installed in 2022\"\"\")\n",
    "found_matches=matcher(doc)\n",
    "for a,b,c in found_matches:\n",
    "    print(f'word id : {a} start at:{b} end at:{c} word is:{doc[b:c]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ebc1004-ab81-4933-ab45-e185a7a6740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[El Clásico,\n",
       " klasiko,\n",
       " klasik,\n",
       " The Classic,\n",
       " El Clàssic,\n",
       " Barcelona and Real Madrid]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher=PhraseMatcher(nlp.vocab)\n",
    "with open('x.txt') as f:\n",
    "    doc=nlp(f.read())\n",
    "phrase_list=['El Clásico','klasiko','klasik','The Classic','El Clàssic','Barcelona and Real Madrid']\n",
    "phrase_patterns=[nlp(text) for text in phrase_list]\n",
    "phrase_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b92dcff4-62a2-4e08-859c-8396292d08b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word id : 9646648106172704443 start at:39 end at:41 word is:both meaning \"The Classic\", is\n"
     ]
    }
   ],
   "source": [
    "matcher.add(\"El_Clásico\",phrase_patterns)\n",
    "\n",
    "matches=matcher(doc)\n",
    "for a,b,c in matches:\n",
    "    print(f'word id : {a} start at:{b} end at:{c} word is:{doc[b-3:c+3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ac8bda-e327-459d-bc24-28b744de0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a77063f7-906d-4a17-b8d8-1dc50fadb124",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'display' from 'IPython.core.display' (C:\\Users\\yousef_haroon\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\display.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m doc=nlp(\u001b[33m'\u001b[39m\u001b[33mApple is going to build a U.K. factory for $6 million.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdisplacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdep\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mjupyter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdistance\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m80\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\spacy\\displacy\\__init__.py:69\u001b[39m, in \u001b[36mrender\u001b[39m\u001b[34m(docs, style, page, minify, jupyter, options, manual)\u001b[39m\n\u001b[32m     65\u001b[39m     html = RENDER_WRAPPER(html)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m jupyter \u001b[38;5;129;01mor\u001b[39;00m (jupyter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_in_jupyter()):\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# return HTML rendered by IPython display()\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# See #4840 for details on span wrapper to disable mathjax\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTML, display\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m display(HTML(\u001b[33m'\u001b[39m\u001b[33m<span class=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtex2jax_ignore\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m</span>\u001b[39m\u001b[33m'\u001b[39m.format(html)))\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m html\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'display' from 'IPython.core.display' (C:\\Users\\yousef_haroon\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\display.py)"
     ]
    }
   ],
   "source": [
    "doc=nlp('Apple is going to build a U.K. factory for $6 million.')\n",
    "displacy.render(doc,style='dep',jupyter=True,options={'distance':80})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fd8b32a-902c-4338-b057-39a19402fa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple      nsubj      nominal subject\n",
      "is         aux        auxiliary\n",
      "going      ROOT       root\n",
      "to         aux        auxiliary\n",
      "build      xcomp      open clausal complement\n",
      "a          det        determiner\n",
      "U.K.       compound   compound\n",
      "factory    dobj       direct object\n",
      "for        prep       prepositional modifier\n",
      "$          quantmod   modifier of quantifier\n",
      "6          compound   compound\n",
      "million    pobj       object of preposition\n",
      ".          punct      punctuation\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text:{10}} {token.dep_:{10}} {spacy.explain(token.dep_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73f7ab93-01ce-47cd-ab7b-a10cf2ef3134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yousef_haroon\\anaconda3\\Lib\\site-packages\\spacy\\displacy\\__init__.py:106: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'display' from 'IPython.core.display' (C:\\Users\\yousef_haroon\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\display.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdisplacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdep\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\spacy\\displacy\\__init__.py:107\u001b[39m, in \u001b[36mserve\u001b[39m\u001b[34m(docs, style, page, minify, options, manual, port, host, auto_select_port)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_in_jupyter():\n\u001b[32m    106\u001b[39m     warnings.warn(Warnings.W011)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mminify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmanual\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m httpd = simple_server.make_server(host, port, app)\n\u001b[32m    109\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mUsing the \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m visualizer\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\spacy\\displacy\\__init__.py:69\u001b[39m, in \u001b[36mrender\u001b[39m\u001b[34m(docs, style, page, minify, jupyter, options, manual)\u001b[39m\n\u001b[32m     65\u001b[39m     html = RENDER_WRAPPER(html)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m jupyter \u001b[38;5;129;01mor\u001b[39;00m (jupyter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_in_jupyter()):\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# return HTML rendered by IPython display()\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# See #4840 for details on span wrapper to disable mathjax\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTML, display\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m display(HTML(\u001b[33m'\u001b[39m\u001b[33m<span class=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtex2jax_ignore\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m</span>\u001b[39m\u001b[33m'\u001b[39m.format(html)))\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m html\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'display' from 'IPython.core.display' (C:\\Users\\yousef_haroon\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\display.py)"
     ]
    }
   ],
   "source": [
    "displacy.serve(doc,style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ad71bc-1dba-4e03-9c8a-1dd40ab78889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
